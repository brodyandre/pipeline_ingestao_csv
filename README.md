# pipeline_ingestao_csv

# ğŸ“Š Pipeline de Dados â€” Transformando Dados Brutos em Insights Valiosos de forma profissional   

![Python](https://img.shields.io/badge/Python-3.10%2B-blue?logo=python)
![Pandas](https://img.shields.io/badge/Pandas-Data%20Processing-orange?logo=pandas)
![SQLite](https://img.shields.io/badge/SQLite-Database-lightgrey?logo=sqlite)
![Airflow](https://img.shields.io/badge/Airflow-Orchestration-red?logo=apacheairflow)
![Status](https://img.shields.io/badge/Status-Em%20Desenvolvimento-yellow)

> **Autor**: [Luiz AndrÃ© de Souza](https://github.com/brodyandre)  

---

## ğŸš€ O que Ã© um Pipeline de Dados?

Um **pipeline de dados** Ã© como uma *fÃ¡brica inteligente* que transforma dados brutos em informaÃ§Ãµes confiÃ¡veis.  

Ele segue **cinco pilares principais**:

1. **IngestÃ£o** â†’ coleta de dados (APIs, CSV, bancos, streams).  
2. **TransformaÃ§Ã£o** â†’ limpeza, padronizaÃ§Ã£o e enriquecimento.  
3. **ValidaÃ§Ã£o** â†’ checagem de integridade e consistÃªncia.  
4. **PersistÃªncia** â†’ armazenamento em bancos de dados ou data lakes.  
5. **Entrega** â†’ relatÃ³rios, dashboards, APIs e arquivos.  

---

## ğŸ—ï¸ Arquitetura de Pipelines Robustos  

AlÃ©m das etapas operacionais, um pipeline de dados **profissional** deve contemplar:  

- âš¡ **OrquestraÃ§Ã£o** â†’ Airflow, Prefect, Dagster, Cron Jobs  
- ğŸ“œ **Logging & Monitoramento** â†’ execuÃ§Ãµes, volumetria, erros  
- ğŸŒ€ **Versionamento** â†’ Git para cÃ³digo, schemas e regras  
- ğŸ§© **ModularizaÃ§Ã£o** â†’ scripts independentes (`extract.py`, `transform.py`, `validate.py` etc.)  
- ğŸ” **SeguranÃ§a** â†’ variÃ¡veis de ambiente, gestÃ£o de permissÃµes  
- ğŸ–¥ï¸ **Ambientes distintos** â†’ DEV, HomologaÃ§Ã£o e ProduÃ§Ã£o  

> ğŸ’¡ *Um pipeline que nÃ£o possui governanÃ§a Ã© apenas um script frÃ¡gil disfarÃ§ado de automaÃ§Ã£o.*

---

## âš™ï¸ Exemplo DidÃ¡tico: Pipeline de IngestÃ£o de dados com ValidaÃ§Ã£o de aquivo CSV  

### ğŸ“Œ Contexto do Problema  
Uma aplicaÃ§Ã£o recebe diariamente um **CSV com dados de usuÃ¡rios** contendo:  

- `id` â†’ Identificador do usuÃ¡rio  
- `nome` â†’ Nome completo  
- `email` â†’ E-mail vÃ¡lido  
- `idade` â†’ Idade declarada  

## Regras de NegÃ³cio:

1 - nenhum campo pode estar vazio;

2 - o campo idade deve conter um valor numÃ©rico vÃ¡lido;

3 - os registros com falhas devem ser descartados automaticamente sem comprometer a carga de dados;

4 - apenas dados Ã­ntegros devem permanecer na base.


## ğŸ¯ Objetivo:  
âœ”ï¸ Validar os dados  
âœ”ï¸ Descartar inconsistÃªncias  
âœ”ï¸ Persistir apenas registros vÃ¡lidos em um banco SQL  


---

## ğŸ”„ Fluxo da SoluÃ§Ã£o  

1. ğŸ“¥ **Leitura segura do CSV**  
2. ğŸ§¹ **RemoÃ§Ã£o de registros incompletos**  
3. ğŸ” **ValidaÃ§Ã£o semÃ¢ntica** (idade numÃ©rica, e-mails vÃ¡lidos)  
4. ğŸ”„ **ConversÃ£o de tipos**  
5. ğŸ—„ï¸ **PersistÃªncia em banco SQL**  
6. ğŸ“‘ **Logs de execuÃ§Ã£o**  

---

## ğŸ’» CÃ³digo Exemplo (Python + Pandas + SQLite)  

```python
import pandas as pd
import sqlite3

# 1. Leitura do CSV
df = pd.read_csv("usuarios.csv", sep=",", encoding="utf-8")

# 2. Remover registros incompletos
df = df.dropna(subset=["nome", "email", "idade"])

# 3. Validar idade como numÃ©rica
df = df[df["idade"].apply(lambda x: str(x).isdigit())]

# 4. Converter idade para inteiro
df["idade"] = df["idade"].astype(int)

# 5. PersistÃªncia em SQLite
conn = sqlite3.connect(":memory:")

df.to_sql("usuarios", conn, index=False, if_exists="replace")

# 6. ValidaÃ§Ã£o da persistÃªncia
print(pd.read_sql_query("SELECT * FROM usuarios", conn))
```

## ğŸ”„ PossÃ­veis ExpansÃµes

ğŸš¨ Armazenar registros invÃ¡lidos em tabela separada

ğŸ“§ Enviar alertas por e-mail em caso de erros

âš™ï¸ Orquestrar com Apache Airflow ou Prefect

## ğŸ“Š Processamento em lotes com chunksize no Pandas


#### ğŸ“‚ Estrutura de RepositÃ³rio

ğŸ“ pipeline-dados-csv
```bash 
 â”œâ”€â”€ extract.py      # IngestÃ£o de dados
 â”œâ”€â”€ transform.py    # Limpeza e transformaÃ§Ã£o
 â”œâ”€â”€ validate.py     # Regras de validaÃ§Ã£o
 â”œâ”€â”€ load.py         # PersistÃªncia em banco
 â”œâ”€â”€ notify.py       # RelatÃ³rios e alertas
 â””â”€â”€ README.md       # DocumentaÃ§Ã£o
```

## ğŸ“Œ Resumo

Um pipeline de dados robusto deve ser:

ğŸ”„ ModularizÃ¡vel

ğŸ§ª TestÃ¡vel

â™»ï¸ Idempotente

ğŸ§­ RastreÃ¡vel

ğŸ“¡ MonitorÃ¡vel

ğŸŒ€ VersionÃ¡vel

ğŸ“ˆ EscalÃ¡vel

ğŸ” Seguro

Com essa estrutura, dados brutos viram informaÃ§Ãµes confiÃ¡veis, escalÃ¡veis e de alto valor.

## âœ¨ Autor

ğŸ‘¤ Luiz AndrÃ© - Data Engineer
ğŸ“Œ GitHub


